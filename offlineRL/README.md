
# ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline Reinforcement Learningï¼‰å­¦ä¹ ç¬”è®°

## ğŸ§  ç®€ä»‹

ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RL æˆ– Batch RLï¼‰è‡´åŠ›äºåœ¨ **ä¸èƒ½ä¸ç¯å¢ƒäº¤äº’** çš„å‰æä¸‹ï¼Œä»…ä¾èµ–ä¸€ä¸ªé™æ€æ•°æ®é›†è¿›è¡Œç­–ç•¥å­¦ä¹ ã€‚ä¸»è¦æŒ‘æˆ˜æ˜¯ **åˆ†å¸ƒåç§»ï¼ˆdistributional shiftï¼‰**ï¼Œå³å­¦ä¹ ç­–ç•¥ä¸æ”¶é›†æ•°æ®çš„è¡Œä¸ºç­–ç•¥ä¸åŒï¼Œå¯¼è‡´ç­–ç•¥æ€§èƒ½é€€åŒ–ã€‚

---

## ğŸ”¥ é‡è¦ç®—æ³•ä¸è®ºæ–‡

### 1. **BCQ (Batch-Constrained deep Q-learning)**
- **è®ºæ–‡**: Fujimoto et al., ICML 2019
- **æ ¸å¿ƒæ€æƒ³**ï¼šé™åˆ¶ç­–ç•¥é€‰æ‹©åªåœ¨æ•°æ®é›†ä¸­å¸¸è§çš„åŠ¨ä½œé™„è¿‘ï¼Œé¿å…ç­–ç•¥äº§ç”Ÿ out-of-distribution è¡Œä¸ºã€‚
- æ–¹æ³•ç»“æ„ï¼šVAE + perturbation model + Q-filter
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/1812.02900)

---

### 2. **BEAR (Bootstrapping Error Accumulation Reduction)**
- **è®ºæ–‡**: Kumar et al., NeurIPS 2019
- ä½¿ç”¨ Kernel MMD é™åˆ¶æ–°ç­–ç•¥ä¸è¦åç¦»è¡Œä¸ºç­–ç•¥ï¼Œä»è€Œå‡å°‘ä¼°å€¼è¯¯å·®ç§¯ç´¯ã€‚
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/1906.00949)

---

### 3. **CQL (Conservative Q-Learning)**
- **è®ºæ–‡**: Kumar et al., NeurIPS 2020
- ä¿å®ˆåœ°ä¼°è®¡ Q å€¼ï¼Œä¸»åŠ¨æƒ©ç½šæ•°æ®å¤–åŠ¨ä½œçš„ Q å€¼ï¼Œä½¿ç­–ç•¥æ›´åŠ ç¨³å¥ã€‚
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2006.04779)

---

### 4. **AWAC (Advantage-Weighted Actor-Critic)**
- **è®ºæ–‡**: Nair et al., arXiv 2020
- ä½¿ç”¨ advantage å¯¹ BC è¿›è¡ŒåŠ æƒï¼Œä½¿ç­–ç•¥æ›´åˆç†åœ°æ›´æ–°ã€‚
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2006.09359)

---

### 5. **DT (Decision Transformer)**
- **è®ºæ–‡**: Chen et al., NeurIPS 2021
- åŸºäº Transformer çš„åºåˆ—å»ºæ¨¡æ–¹æ³•ï¼Œè¾“å…¥ return + (state, action) åºåˆ—ã€‚
- å¼€åˆ›äº†å°† Offline RL å»ºæ¨¡ä¸ºåºåˆ—å»ºæ¨¡çš„æ–¹å‘ã€‚
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2106.01345)

---

### 6. **TD3+BC**
- **è®ºæ–‡**: Fujimoto & Gu, NeurIPS 2021
- åœ¨ TD3 çš„ actor æ›´æ–°ä¸­åŠ å…¥ behavior cloning lossï¼Œæ›´ç¨³å®šåœ°è¿›è¡Œç­–ç•¥å­¦ä¹ ã€‚
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2106.06860)

---

### 7. **IQL (Implicit Q-Learning)**
- **è®ºæ–‡**: Kostrikov et al., ICLR 2022
- æ— éœ€æ˜ç¡®æçº¯ç­–ç•¥ï¼Œç›´æ¥ä» Q å‡½æ•°æå– actorã€‚è®­ç»ƒç¨³å®šã€æ•ˆæœå¥½ã€‚
- ğŸ”— [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2110.06169)

---

## ğŸ“¦ å¸¸ç”¨æ•°æ®é›†

### D4RL (Datasets for Deep Data-Driven RL)
æä¾› MuJoCoã€AntMazeã€Minigridã€Atari ç­‰ç¦»çº¿æ•°æ®é›†ã€‚

- ğŸ”— [GitHub: D4RL](https://github.com/rail-berkeley/d4rl)

---

## ğŸ“š å­¦ä¹ æ¸…å•ä¸æ¨èè·¯çº¿

### ğŸ§© Step 1: ç†è§£ç¦»çº¿ RL é—®é¢˜
- âœ… é˜…è¯»ç»¼è¿°ï¼š[Offline Reinforcement Learning: Tutorial, Review, and Perspectives](https://arxiv.org/abs/2005.01643)
- âœ… ç†è§£ç¦»çº¿ RL ç›¸æ¯”åœ¨çº¿ RL çš„ä¸»è¦åŒºåˆ«ï¼šdistribution shift, extrapolation error

### ğŸ§ª Step 2: å…¥é—¨ç»å…¸æ–¹æ³•
- âœ… é˜…è¯» BCQ, BEAR, CQL ä¸‰ç¯‡ç»å…¸è®ºæ–‡
- âœ… å®ç° BCQ æˆ– CQLï¼ˆæ¨èä» [d3rlpy](https://github.com/takuseno/d3rlpy) æˆ– [CleanRL](https://github.com/vwxyzjn/cleanrl) å¼€å§‹ï¼‰

### ğŸ¤– Step 3: Transformer æ–¹æ³•
- âœ… é˜…è¯» Decision Transformer è®ºæ–‡
- âœ… å­¦ä¹  HuggingFace çš„ [Decision Transformer å®ç°](https://huggingface.co/blog/decision-transformer)

### ğŸ“Š Step 4: åº”ç”¨ä¸å®è·µ
- âœ… ä¸‹è½½å¹¶ä½¿ç”¨ D4RL æ•°æ®é›†ï¼Œå¤ç°å®éªŒ
- âœ… æ¢ç´¢åŒ»ç–—/æ¨èç³»ç»Ÿç­‰ Offline RL åº”ç”¨åœºæ™¯

---

## ğŸ§­ æ–¹æ³•ç»“æ„æ€»ç»“

```
ç¦»çº¿RLä¸»æµæ–¹æ³•åˆ†ç±»ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Value-based æ–¹æ³•        â”‚
â”‚   - BCQ, BEAR, CQL        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Actor-Critic æ–¹æ³•        â”‚
â”‚   - AWAC, IQL, TD3+BC      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Sequence modeling æ–¹æ³•    â”‚
â”‚   - Decision Transformer    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“˜ å‚è€ƒèµ„æº

- Berkeley CS285 è¯¾ç¨‹ï¼š[Deep RL](http://rail.eecs.berkeley.edu/deeprlcourse/)
- NeurIPS/ICLR ä¼šè®®è®ºæ–‡é›†
- GitHub: [d3rlpy](https://github.com/takuseno/d3rlpy), [CleanRL](https://github.com/vwxyzjn/cleanrl)
